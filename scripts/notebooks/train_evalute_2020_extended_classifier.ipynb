{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trains and evaluate the 2020 extended classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.datasets.visual_behavior_extended_dataset import VisualBehaviorExtendedDataset\n",
    "from deepcell.trainer import Trainer\n",
    "from deepcell.inference import cv_performance\n",
    "from deepcell.models.classifier import Classifier\n",
    "from deepcell.data_splitter import DataSplitter\n",
    "from deepcell.transform import Transform\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from imgaug import augmenters as iaa\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git rev-parse --short HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_DESTINATION = Path('/tmp/artifacts')\n",
    "CHECKPOINT_PATH = Path('.').absolute().parent.parent / 'saved_models' / '022122_lr1e-4_wd_0_linear_classifier_upto_layer_22_freeze_upto_8_dropout_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VisualBehaviorExtendedDataset(artifact_destination=ARTIFACT_DESTINATION, \n",
    "                                        exclude_projects=[\n",
    "                                            'ophys-experts-go-big-or-go-home',\n",
    "                                            'ophys-experts-slc-oct-2020_ophys-experts-go-big-or-go-home', \n",
    "                                            'ophys-expert-danielsf-additions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.project_meta.groupby('project_name')['date'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.project_meta.groupby('project_name').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transform = transforms.Compose([\n",
    "    iaa.Sequential([\n",
    "        iaa.Affine(\n",
    "            rotate=[0, 90, 180, 270, -90, -180, -270], order=0\n",
    "        ),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.CenterCropToFixedSize(height=128, width=128),\n",
    "    ]).augment_image,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_transform = Transform(all_transform=all_transform)\n",
    "\n",
    "all_transform = transforms.Compose([\n",
    "    iaa.Sequential([\n",
    "        iaa.CenterCropToFixedSize(height=128, width=128)\n",
    "    ]).augment_image,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = Transform(all_transform=all_transform)\n",
    "\n",
    "data_splitter = DataSplitter(model_inputs=dataset.dataset, train_transform=train_transform,\n",
    "                             test_transform=test_transform, seed=1234, image_dim=(128, 128), \n",
    "                             use_correlation_projection=True)\n",
    "train, test = data_splitter.get_train_test_split(test_size=.3)\n",
    "\n",
    "print(len(train) + len(test))\n",
    "print(train.y.mean())\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg11_bn(pretrained=True, progress=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg11_bn(pretrained=True, progress=False)\n",
    "model = Classifier(model=model, truncate_to_layer=22, freeze_up_to_layer=8,\n",
    "                  classifier_cfg=[], dropout_prob=0.0,\n",
    "                  final_activation_map_spatial_dimensions=(1, 1))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = lambda: torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "scheduler = lambda optimizer: torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=15, verbose=True, factor=.5)\n",
    "trainer = Trainer(model=model, n_epochs=1000, optimizer=optimizer, scheduler=scheduler,\n",
    "                        criterion=criterion, save_path=f'{CHECKPOINT_PATH}',\n",
    "                        early_stopping=30)\n",
    "cv_metrics = trainer.cross_validate(train_dataset=train, data_splitter=data_splitter, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=1, figsize=(5, 20))\n",
    "\n",
    "for i in range(5):\n",
    "    x = torch.load(f'{CHECKPOINT_PATH}/{i}_model.pt')\n",
    "    ax[i].plot(x['performance']['train']['f1s'], label='train')\n",
    "    ax[i].plot(x['performance']['val']['f1s'], label='val')\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel('Epoch')\n",
    "    ax[i].set_ylabel('F1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=1, figsize=(5, 20))\n",
    "\n",
    "for i in range(5):\n",
    "    x = torch.load(f'{CHECKPOINT_PATH}/{i}_model.pt')\n",
    "    ax[i].plot(x['performance']['train']['losses'], label='train')\n",
    "    ax[i].plot(x['performance']['val']['losses'], label='val')\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel('Epoch')\n",
    "    ax[i].set_ylabel('loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=1, figsize=(5, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    ax[i].plot(cv_metrics.train_metrics[i].auprs[:cv_metrics.train_metrics[i].best_epoch + 60], label='train')\n",
    "    ax[i].plot(cv_metrics.valid_metrics[i].auprs[:cv_metrics.train_metrics[i].best_epoch + 60], label='val')\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel('Epoch')\n",
    "    ax[i].set_ylabel('AUPR')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg11_bn(pretrained=True, progress=False)\n",
    "model = Classifier(model=model, truncate_to_layer=15, classifier_cfg=[1024, 1024])\n",
    "preds, metrics = cv_performance(model=model, data_splitter=data_splitter,\n",
    "                            train=train, checkpoint_path=f'{CHECKPOINT_PATH}')\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d11df1f2a4c94e315a94878862fd61771c95a536372aa1cec6a10c97581647b"
  },
  "kernelspec": {
   "display_name": "conda_py38",
   "language": "python",
   "name": "conda_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}